import torch
import torch.nn.functional as F
import torchvision.transforms as transforms
from PIL import Image
import os
import json
from tqdm import tqdm
import numpy as np
import cv2

# âœ… ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
MODEL_PATH = "model/CelebDF_model_20_epochs_99acc.pt"
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# âœ… ëª¨ë¸ ë¡œë“œ
checkpoint = torch.load(MODEL_PATH, map_location=device)
model = checkpoint['model']
model.load_state_dict(checkpoint['model_state_dict'])
model = model.to(device, memory_format=torch.channels_last)
model.eval()

# âœ… ë§ˆì§€ë§‰ Convolutional Layer ì„¤ì • (XceptionNet êµ¬ì¡°ì— ë§ê²Œ ìˆ˜ì •)
target_layer = model.conv4  # ğŸš© ëª¨ë¸ êµ¬ì¡°ì— ë”°ë¼ ë³€ê²½ í•„ìš”

# âœ… ì´ë¯¸ì§€ ì „ì²˜ë¦¬
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
])

# âœ… GradCAM ìƒì„± í•¨ìˆ˜
def generate_gradcam(input_tensor, model, target_layer):
    gradients = []
    activations = []

    def forward_hook(module, input, output):
        activations.append(output)

    def backward_hook(module, grad_in, grad_out):
        gradients.append(grad_out[0])

    # âœ… Hook ë“±ë¡
    forward_handle = target_layer.register_forward_hook(forward_hook)
    backward_handle = target_layer.register_full_backward_hook(backward_hook)  # ì—¬ê¸°ë¥¼ ìˆ˜ì •

    # âœ… Forward Pass
    output = model(input_tensor)
    model.zero_grad()

    # âœ… Backward Pass
    target = output[:, 0]  # í´ë˜ìŠ¤ 0ì„ ëŒ€ìƒìœ¼ë¡œ (ë”¥í˜ì´í¬ í™•ë¥ )
    target.backward()

    # âœ… Hook ì œê±°
    forward_handle.remove()
    backward_handle.remove()

    # âœ… í™œì„±í™” ë° Gradient ìˆ˜ì§‘
    activation = activations[0].squeeze(0).cpu().detach().numpy()
    gradient = gradients[0].squeeze(0).cpu().detach().numpy()

    # âœ… Grad-CAM ê³„ì‚°
    weights = np.mean(gradient, axis=(1, 2))  # Global Average Pooling
    gradcam = np.maximum(np.sum(weights[:, np.newaxis, np.newaxis] * activation, axis=0), 0)

    # âœ… ì •ê·œí™”
    gradcam = (gradcam - gradcam.min()) / (gradcam.max() - gradcam.min() + 1e-8)
    gradcam = cv2.resize(gradcam, (224, 224))

    return gradcam



# âœ… GradCAM ê²°ê³¼ë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜
def apply_gradcam_overlay(image_path, heatmap):
    img = cv2.imread(image_path)
    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))
    heatmap = np.uint8(255 * heatmap)
    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)

    overlay = cv2.addWeighted(img, 0.6, heatmap, 0.4, 0)
    return overlay

# âœ… ì´ë¯¸ì§€ ë¡œë“œ (ë°°ì¹˜ ë‹¨ìœ„)
def load_images_in_batches(image_paths, batch_size=16):
    for i in range(0, len(image_paths), batch_size):
        batch_paths = image_paths[i: i + batch_size]
        images = [transform(Image.open(img_path).convert("RGB")) for img_path in batch_paths]
        yield torch.stack(images).to(device), batch_paths

# âœ… ì˜ˆì¸¡ í•¨ìˆ˜
def predict(images_tensor):
    with torch.no_grad():
        outputs = model(images_tensor)
        probabilities = torch.sigmoid(outputs).cpu().numpy()
    return probabilities

# âœ… ì „ì²´ í”„ë ˆì„ ì²˜ë¦¬
def process_all_frames(input_folder, output_file, batch_size=16, use_gradcam=False):
    image_files = sorted([os.path.join(input_folder, f) for f in os.listdir(input_folder) if f.endswith(".jpg")])
    if not image_files:
        print("âŒ ì´ë¯¸ì§€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    results = {}
    for batch_images, batch_paths in tqdm(load_images_in_batches(image_files, batch_size), total=len(image_files) // batch_size + 1, desc="ğŸ” Processing"):
        probs = predict(batch_images)
        for path, img_tensor, prob in zip(batch_paths, batch_images, probs):
            frame_name = os.path.basename(path)
            result_data = {"probability": float(prob)}

            # âœ… GradCAM ì ìš© ì—¬ë¶€
            if use_gradcam:
                heatmap = generate_gradcam(img_tensor, model, target_layer)
                gradcam_image = apply_gradcam_overlay(path, heatmap)

                # âœ… GradCAM ì´ë¯¸ì§€ ì €ì¥
                gradcam_filename = f"{os.path.splitext(frame_name)[0]}_gradcam.jpg"
                gradcam_path = os.path.join(input_folder, gradcam_filename)
                cv2.imwrite(gradcam_path, gradcam_image)

                # âœ… JSONì— GradCAM ê²½ë¡œ ì¶”ê°€
                result_data["gradcam_path"] = gradcam_path

            results[frame_name] = result_data

    with open(output_file, "w") as f:
        json.dump(results, f, indent=4)
    print(f"âœ… ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_file}")

# âœ… ì‹¤í–‰ ì˜ˆì‹œ (Main)
if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="ë”¥í˜ì´í¬ í”„ë ˆì„ ë¶„ì„ê¸° (CelebDF_model_20_epochs_99acc ëª¨ë¸)")
    parser.add_argument("--input", type=str, required=True, help="í”„ë ˆì„ì´ ì €ì¥ëœ í´ë” ê²½ë¡œ")
    parser.add_argument("--output", type=str, default="results/deepfake_results.json", help="ê²°ê³¼ ì €ì¥ íŒŒì¼")
    parser.add_argument("--batch_size", type=int, default=16, help="ë°°ì¹˜ í¬ê¸° (ê¸°ë³¸ê°’: 16)")
    parser.add_argument("--use_gradcam", action="store_true", help="GradCAM ì ìš© ì—¬ë¶€ (ì˜µì…˜ ì„ íƒ ì‹œ ì ìš©)")

    args = parser.parse_args()
    process_all_frames(args.input, args.output, args.batch_size, args.use_gradcam)
